## 3.大模型优化与AI应用 

### 3.1 相关学习资料

#### 3.1.1传统机器学习与深度学习

1. 林伟伟. 云计算与AI应用技术. 清华大学出版社. 2023.07
2. tangyudi/Ai-Learn：人工智能学习路线图，整理近200个实战案例与项目，https://github.com/tangyudi/Ai-Learn
3. 《机器学习》（周志华）：经典入门教材，涵盖基础算法与理论，附带南瓜书（Datawhale 开源项目）提供公式推导解析，https://github.com/datawhalechina/pumpkin-book
4. 《统计学习方法》（李航）：聚焦统计学习算法的数学推导，适合进阶理解，https://book.douban.com/subject/10706114/
5. 《Deep Learning》（花书）：Goodfellow 等著，深度学习理论权威，开源电子版可在线阅读，https://www.deeplearningbook.org/
6. Keras 官方示例：简单易用的深度学习框架，提供图像分类、序列预测等实战案例，https://keras.io/examples/
7. Andrew Ng 机器学习课程：Coursera 经典课程，附带 Python/Matlab 代码练习，https://www.coursera.org/learn/machine-learning

#### 3.1.2大模型

1. Hoper-J/AI-Guide-and-Demos-zh_CN：一份入门AI/LLM大模型的逐步指南，包含教程和演示代码，带你从API走进本地大模型部署和微调，https://github.com/Hoper-J/AI-Guide-and-Demos-zh_CN
2. Hugging Face Transformers：一站式 NLP 工具库，含 BERT、GPT 等模型实现及教程，https://github.com/huggingface/transformers
3. 《大语言模型》经典图书，由作者赵鑫，李军毅，周昆，唐天一，文继荣 等作者编写，全面介绍了大型语言模型的技术背景、发展过程、关键技术、资源、预训练方法、微调与对齐技术、使用方法、评测以及应用等多个方面。https://llmbook-zh.github.io/

#### 3.1.3其他大模型学习资源

https://docs.google.com/document/d/1TWgjU9hV0XPo2gsXWexoULUe6rW_u7dbtkAzxbyKr_g/edit?usp=sharing

### 3.2 实验室相关成果

#### 3.2.1传统机器学习与深度学习

1. Haijie Wu, Lin, Weiwei*, Yuehong Chen, Fang Shi, Wangbo Shen, C. L. Philip Chen. Adaptive Incremental Broad Learning System Based on Interval Type-2 Fuzzy Set with Automatic Determination of Hyperparameters.  IEEE Transactions on Fuzzy Systems, 2025: 1–13
2. Peng Peng, Yuehong Chen, Weiwei Lin*, James Z. Wang. Attention-based CNN–LSTM for high-frequency multiple cryptocurrency trend prediction.  Expert Systems with Applications, 2024, 237: 121520
3. Wangbo Shen, Weiwei Lin*, Yulei Wu, Fang Shi, Wentai Wu, Keqin Li. Evolving Deep Multiple Kernel Learning Networks through Genetic Algorithms.  IEEE Transactions on Industrial Informatics, 2023,2(19):1569 - 1580

#### 3.2.2大模型

1. Li Y, Yang L, Shen W, et al. CrowdSelect: Synthetic Instruction Data Selection with Multi-LLM Wisdom[J]. arXiv preprint arXiv:2503.01836, 2025.
2. Liu G, Lin W, Huang T, et al. Targeted vaccine: Safety alignment for large language models against harmful fine-tuning via layer-wise perturbation[J]. arXiv preprint arXiv:2410.09760, 2024.